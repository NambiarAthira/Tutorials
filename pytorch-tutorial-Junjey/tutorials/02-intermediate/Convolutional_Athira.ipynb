{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 60000 images\n",
      "test : 10000 images\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='./mnist', train=True,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "print(\"train : \" + str(len(trainset)) + ' images')\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./mnist', train=False,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "print(\"test : \" + str(len(testset)) + ' images')\n",
    "\n",
    "# Data loader\n",
    "trainloader = torch.utils.data.DataLoader(dataset=trainset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(dataset=testset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    #define the learnable paramters by calling the respective modules (nn.Conv2d, nn.MaxPool2d etc.)\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #calling conv2d module for convolution\n",
    "        self.layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "                        nn.BatchNorm2d(16),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "                        nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.fc=nn.Linear(32*7*7,num_classes)\n",
    "        \n",
    "    \n",
    "    #defining the structure of the network\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        out = self.fc(x)\n",
    "        return out#,resp2,resp2,resp4\n",
    "                        \n",
    "\n",
    "model = Net()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "#Printing the network architecture\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0191, -0.0233,  0.0153,  ..., -0.0242, -0.0243,  0.0151],\n",
       "        [-0.0155,  0.0071,  0.0111,  ...,  0.0135,  0.0095,  0.0186],\n",
       "        [-0.0133, -0.0251,  0.0213,  ..., -0.0158,  0.0126,  0.0239],\n",
       "        ...,\n",
       "        [ 0.0197, -0.0050,  0.0043,  ..., -0.0096, -0.0039,  0.0139],\n",
       "        [-0.0061, -0.0199,  0.0120,  ..., -0.0006,  0.0088,  0.0148],\n",
       "        [-0.0104,  0.0186, -0.0119,  ...,  0.0039,  0.0214,  0.0003]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Train the network\n",
    "# ^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "def train(epoch, trainloader, optimizer, criterion):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (inputs,labels) in enumerate(tqdm(trainloader), 0):\n",
    "        # get the inputs\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "            \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # addup loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('epoch %d training loss: %.3f' %\n",
    "            (epoch + 1, running_loss / (len(trainloader))))\n",
    "    return running_loss / (len(trainloader))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Let us look at how the network performs on the test dataset.\n",
    "\n",
    "def test(testloader, model):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for (inputs,labels) in tqdm(testloader):\n",
    "            # get the inputs\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # addup loss\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the %d test images: %d %%, loss = %f' % (\n",
    "                                    len(testset),100 * correct / total, running_loss / len(testloader)))\n",
    "    return running_loss / len(testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "print('Start Training')\n",
    "# if not os.path.exists('./models'):\n",
    "#     os.mkdir('./models')\n",
    "\n",
    "training_losses = []\n",
    "testing_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    print('epoch ', epoch + 1)\n",
    "    train_loss = train(epoch, trainloader, optimizer, criterion)\n",
    "    test_loss = test(testloader, model)\n",
    "#     classwise_test(testloader, net)\n",
    "    \n",
    "    \n",
    "    training_losses.append(train_loss)\n",
    "    testing_losses.append(test_loss)\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running_loss=0\n",
    "# dataiter = iter(testloader)\n",
    "# inputs, labels = dataiter.next()\n",
    "# inputs=inputs.to(device)\n",
    "# labels=labels.to(device)\n",
    "# outputs = model(inputs)\n",
    "# loss = criterion(outputs, labels)\n",
    "# running_loss += loss.item()\n",
    "\n",
    "# correct=(predicted==labels).sum().item()\n",
    "# total=inputs.size(0)\n",
    "# a,pred=torch.max(outputs,1)\n",
    "# pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Torch tensor\n",
    "# x=torch.randn(2,3)\n",
    "# print(x)\n",
    "# print(type(x))\n",
    "\n",
    "# #Torch tensor to numpy\n",
    "# xnp=x.numpy()\n",
    "# print(xnp)\n",
    "# print(type(xnp))\n",
    "\n",
    "# #Numpy to Torch tensor\n",
    "# xx=torch.from_numpy(xnp)\n",
    "# print(xx)\n",
    "# print(type(xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Transposing axis\n",
    "\n",
    "# from skimage import io\n",
    "# np_img = io.imread('./data/ferrari.png')\n",
    "# print(np_img.shape)\n",
    "\n",
    "# np_img = np_img.transpose((2,0,1))\n",
    "# print(np_img.shape)\n",
    "\n",
    "# torch_img = torch.from_numpy(np_img)\n",
    "# print(torch_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels = iter(dataloader).next()\n",
    "# print(type(images))\n",
    "\n",
    "#Unsqueeze\n",
    "# unsqueezed_img = images[0].unsqueeze(0)\n",
    "# print(unsqueezed_img.shape)\n",
    "\n",
    "# #Squeeze\n",
    "# squeezed_img = images[0].squeeze(0)\n",
    "# print(squeezed_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
