{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : 60000 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/athira/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/athira/anaconda3/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/15], Step [10/469], Reconst Loss: 35318.1641, KL Div: 3802.9487\n",
      "Epoch[1/15], Step [20/469], Reconst Loss: 29716.2695, KL Div: 1105.4612\n",
      "Epoch[1/15], Step [30/469], Reconst Loss: 26501.5625, KL Div: 1300.5052\n",
      "Epoch[1/15], Step [40/469], Reconst Loss: 27156.9336, KL Div: 674.8234\n",
      "Epoch[1/15], Step [50/469], Reconst Loss: 26209.9609, KL Div: 813.1757\n",
      "Epoch[1/15], Step [60/469], Reconst Loss: 25954.8965, KL Div: 866.1167\n",
      "Epoch[1/15], Step [70/469], Reconst Loss: 25533.9551, KL Div: 851.5728\n",
      "Epoch[1/15], Step [80/469], Reconst Loss: 24946.6641, KL Div: 927.5524\n",
      "Epoch[1/15], Step [90/469], Reconst Loss: 22866.5234, KL Div: 1067.9318\n",
      "Epoch[1/15], Step [100/469], Reconst Loss: 21587.6445, KL Div: 1395.4412\n",
      "Epoch[1/15], Step [110/469], Reconst Loss: 22389.6934, KL Div: 1339.3346\n",
      "Epoch[1/15], Step [120/469], Reconst Loss: 21160.7891, KL Div: 1617.3932\n",
      "Epoch[1/15], Step [130/469], Reconst Loss: 19963.0586, KL Div: 1761.6270\n",
      "Epoch[1/15], Step [140/469], Reconst Loss: 19130.1074, KL Div: 1772.9781\n",
      "Epoch[1/15], Step [150/469], Reconst Loss: 20688.6582, KL Div: 1798.2626\n",
      "Epoch[1/15], Step [160/469], Reconst Loss: 18725.7500, KL Div: 1749.6515\n",
      "Epoch[1/15], Step [170/469], Reconst Loss: 18232.9961, KL Div: 1791.5327\n",
      "Epoch[1/15], Step [180/469], Reconst Loss: 18361.9863, KL Div: 1870.7896\n",
      "Epoch[1/15], Step [190/469], Reconst Loss: 17529.7129, KL Div: 1974.4775\n",
      "Epoch[1/15], Step [200/469], Reconst Loss: 17619.2969, KL Div: 1846.7480\n",
      "Epoch[1/15], Step [210/469], Reconst Loss: 17723.6504, KL Div: 2047.6448\n",
      "Epoch[1/15], Step [220/469], Reconst Loss: 17349.8086, KL Div: 2095.6257\n",
      "Epoch[1/15], Step [230/469], Reconst Loss: 17437.5020, KL Div: 2053.0383\n",
      "Epoch[1/15], Step [240/469], Reconst Loss: 16668.2930, KL Div: 2460.1895\n",
      "Epoch[1/15], Step [250/469], Reconst Loss: 15950.9131, KL Div: 2177.1482\n",
      "Epoch[1/15], Step [260/469], Reconst Loss: 15655.4678, KL Div: 2121.5276\n",
      "Epoch[1/15], Step [270/469], Reconst Loss: 16653.3809, KL Div: 2343.4546\n",
      "Epoch[1/15], Step [280/469], Reconst Loss: 15358.8066, KL Div: 2295.0073\n",
      "Epoch[1/15], Step [290/469], Reconst Loss: 15490.5791, KL Div: 2382.0601\n",
      "Epoch[1/15], Step [300/469], Reconst Loss: 15707.3496, KL Div: 2402.8867\n",
      "Epoch[1/15], Step [310/469], Reconst Loss: 14877.0781, KL Div: 2422.0288\n",
      "Epoch[1/15], Step [320/469], Reconst Loss: 15131.4316, KL Div: 2395.7012\n",
      "Epoch[1/15], Step [330/469], Reconst Loss: 14688.2500, KL Div: 2462.1941\n",
      "Epoch[1/15], Step [340/469], Reconst Loss: 15394.9824, KL Div: 2550.4133\n",
      "Epoch[1/15], Step [350/469], Reconst Loss: 14514.1367, KL Div: 2385.9912\n",
      "Epoch[1/15], Step [360/469], Reconst Loss: 14529.2627, KL Div: 2599.5627\n",
      "Epoch[1/15], Step [370/469], Reconst Loss: 14564.4961, KL Div: 2587.4282\n",
      "Epoch[1/15], Step [380/469], Reconst Loss: 14137.0762, KL Div: 2614.7437\n",
      "Epoch[1/15], Step [390/469], Reconst Loss: 14762.3750, KL Div: 2545.7393\n",
      "Epoch[1/15], Step [400/469], Reconst Loss: 14314.1074, KL Div: 2687.1006\n",
      "Epoch[1/15], Step [410/469], Reconst Loss: 14331.1338, KL Div: 2590.6726\n",
      "Epoch[1/15], Step [420/469], Reconst Loss: 14315.6484, KL Div: 2562.0190\n",
      "Epoch[1/15], Step [430/469], Reconst Loss: 13826.0469, KL Div: 2667.9565\n",
      "Epoch[1/15], Step [440/469], Reconst Loss: 13594.1191, KL Div: 2747.9424\n",
      "Epoch[1/15], Step [450/469], Reconst Loss: 13451.2031, KL Div: 2600.9438\n",
      "Epoch[1/15], Step [460/469], Reconst Loss: 13552.6162, KL Div: 2661.3428\n",
      "Epoch[2/15], Step [10/469], Reconst Loss: 13815.0596, KL Div: 2747.8760\n",
      "Epoch[2/15], Step [20/469], Reconst Loss: 13909.0801, KL Div: 2699.1323\n",
      "Epoch[2/15], Step [30/469], Reconst Loss: 12995.6982, KL Div: 2719.0266\n",
      "Epoch[2/15], Step [40/469], Reconst Loss: 13144.5059, KL Div: 2594.1582\n",
      "Epoch[2/15], Step [50/469], Reconst Loss: 13066.1338, KL Div: 2840.6882\n",
      "Epoch[2/15], Step [60/469], Reconst Loss: 13331.9590, KL Div: 2619.0137\n",
      "Epoch[2/15], Step [70/469], Reconst Loss: 13291.1260, KL Div: 2803.4314\n",
      "Epoch[2/15], Step [80/469], Reconst Loss: 13433.2344, KL Div: 2839.5588\n",
      "Epoch[2/15], Step [90/469], Reconst Loss: 13939.8496, KL Div: 2889.6626\n",
      "Epoch[2/15], Step [100/469], Reconst Loss: 13343.9131, KL Div: 2753.7363\n",
      "Epoch[2/15], Step [110/469], Reconst Loss: 13082.3281, KL Div: 2901.4844\n",
      "Epoch[2/15], Step [120/469], Reconst Loss: 13084.0830, KL Div: 2795.2671\n",
      "Epoch[2/15], Step [130/469], Reconst Loss: 12544.9004, KL Div: 2825.2834\n",
      "Epoch[2/15], Step [140/469], Reconst Loss: 13193.9219, KL Div: 2902.9055\n",
      "Epoch[2/15], Step [150/469], Reconst Loss: 13321.4922, KL Div: 2940.0164\n",
      "Epoch[2/15], Step [160/469], Reconst Loss: 12995.2246, KL Div: 2982.7959\n",
      "Epoch[2/15], Step [170/469], Reconst Loss: 12973.3057, KL Div: 2872.8789\n",
      "Epoch[2/15], Step [180/469], Reconst Loss: 13273.2422, KL Div: 2899.9668\n",
      "Epoch[2/15], Step [190/469], Reconst Loss: 12680.7402, KL Div: 2860.7683\n",
      "Epoch[2/15], Step [200/469], Reconst Loss: 12312.0068, KL Div: 2946.8760\n",
      "Epoch[2/15], Step [210/469], Reconst Loss: 12164.6016, KL Div: 2791.5259\n",
      "Epoch[2/15], Step [220/469], Reconst Loss: 12594.3232, KL Div: 2825.6733\n",
      "Epoch[2/15], Step [230/469], Reconst Loss: 12675.8164, KL Div: 2967.3032\n",
      "Epoch[2/15], Step [240/469], Reconst Loss: 12543.0850, KL Div: 2808.0918\n",
      "Epoch[2/15], Step [250/469], Reconst Loss: 12260.3789, KL Div: 2964.0854\n",
      "Epoch[2/15], Step [260/469], Reconst Loss: 12561.6445, KL Div: 2980.2339\n",
      "Epoch[2/15], Step [270/469], Reconst Loss: 12276.0938, KL Div: 2972.1914\n",
      "Epoch[2/15], Step [280/469], Reconst Loss: 12493.3506, KL Div: 2836.4961\n",
      "Epoch[2/15], Step [290/469], Reconst Loss: 11566.6191, KL Div: 2919.1677\n",
      "Epoch[2/15], Step [300/469], Reconst Loss: 12387.9258, KL Div: 3031.7866\n",
      "Epoch[2/15], Step [310/469], Reconst Loss: 12678.4453, KL Div: 3005.3662\n",
      "Epoch[2/15], Step [320/469], Reconst Loss: 12529.0703, KL Div: 3009.6665\n",
      "Epoch[2/15], Step [330/469], Reconst Loss: 12469.9336, KL Div: 2981.4180\n",
      "Epoch[2/15], Step [340/469], Reconst Loss: 11833.6211, KL Div: 3029.8169\n",
      "Epoch[2/15], Step [350/469], Reconst Loss: 12308.6328, KL Div: 2919.0903\n",
      "Epoch[2/15], Step [360/469], Reconst Loss: 12329.0830, KL Div: 3002.0491\n",
      "Epoch[2/15], Step [370/469], Reconst Loss: 11650.3164, KL Div: 2892.4751\n",
      "Epoch[2/15], Step [380/469], Reconst Loss: 11634.7734, KL Div: 2941.8057\n",
      "Epoch[2/15], Step [390/469], Reconst Loss: 12447.5859, KL Div: 3010.7761\n",
      "Epoch[2/15], Step [400/469], Reconst Loss: 11831.7754, KL Div: 3034.7246\n",
      "Epoch[2/15], Step [410/469], Reconst Loss: 11751.4727, KL Div: 2920.4097\n",
      "Epoch[2/15], Step [420/469], Reconst Loss: 12157.5859, KL Div: 3080.9961\n",
      "Epoch[2/15], Step [430/469], Reconst Loss: 11930.6484, KL Div: 2866.1304\n",
      "Epoch[2/15], Step [440/469], Reconst Loss: 11781.2979, KL Div: 2962.8110\n",
      "Epoch[2/15], Step [450/469], Reconst Loss: 12027.6914, KL Div: 3077.8230\n",
      "Epoch[2/15], Step [460/469], Reconst Loss: 11836.5645, KL Div: 2997.3257\n",
      "Epoch[3/15], Step [10/469], Reconst Loss: 11759.0342, KL Div: 3065.3018\n",
      "Epoch[3/15], Step [20/469], Reconst Loss: 11783.8203, KL Div: 2982.9634\n",
      "Epoch[3/15], Step [30/469], Reconst Loss: 11390.3750, KL Div: 3059.3130\n",
      "Epoch[3/15], Step [40/469], Reconst Loss: 11419.4590, KL Div: 2998.3125\n",
      "Epoch[3/15], Step [50/469], Reconst Loss: 12221.3906, KL Div: 3162.5601\n",
      "Epoch[3/15], Step [60/469], Reconst Loss: 11979.7568, KL Div: 3051.6064\n",
      "Epoch[3/15], Step [70/469], Reconst Loss: 11586.9326, KL Div: 2977.2598\n",
      "Epoch[3/15], Step [80/469], Reconst Loss: 12348.2910, KL Div: 3092.8071\n",
      "Epoch[3/15], Step [90/469], Reconst Loss: 11353.5215, KL Div: 3101.3259\n",
      "Epoch[3/15], Step [100/469], Reconst Loss: 12159.4102, KL Div: 3067.1328\n",
      "Epoch[3/15], Step [110/469], Reconst Loss: 12608.4482, KL Div: 2986.2078\n",
      "Epoch[3/15], Step [120/469], Reconst Loss: 11618.9844, KL Div: 3145.6086\n",
      "Epoch[3/15], Step [130/469], Reconst Loss: 11493.9551, KL Div: 3040.8396\n",
      "Epoch[3/15], Step [140/469], Reconst Loss: 11876.0586, KL Div: 3039.0625\n",
      "Epoch[3/15], Step [150/469], Reconst Loss: 11796.2539, KL Div: 3164.6667\n",
      "Epoch[3/15], Step [160/469], Reconst Loss: 11388.7354, KL Div: 3014.6616\n",
      "Epoch[3/15], Step [170/469], Reconst Loss: 11593.1514, KL Div: 3015.5645\n",
      "Epoch[3/15], Step [180/469], Reconst Loss: 11538.4277, KL Div: 3065.8608\n",
      "Epoch[3/15], Step [190/469], Reconst Loss: 11701.6309, KL Div: 3038.5872\n",
      "Epoch[3/15], Step [200/469], Reconst Loss: 11544.6113, KL Div: 2987.5835\n",
      "Epoch[3/15], Step [210/469], Reconst Loss: 11584.8896, KL Div: 3083.1411\n",
      "Epoch[3/15], Step [220/469], Reconst Loss: 11745.8008, KL Div: 3101.1323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3/15], Step [230/469], Reconst Loss: 11413.7021, KL Div: 3069.2979\n",
      "Epoch[3/15], Step [240/469], Reconst Loss: 11618.3340, KL Div: 3177.3115\n",
      "Epoch[3/15], Step [250/469], Reconst Loss: 11701.7666, KL Div: 3117.1934\n",
      "Epoch[3/15], Step [260/469], Reconst Loss: 11297.5850, KL Div: 3178.6416\n",
      "Epoch[3/15], Step [270/469], Reconst Loss: 11520.6934, KL Div: 3109.1050\n",
      "Epoch[3/15], Step [280/469], Reconst Loss: 11804.8027, KL Div: 3077.6218\n",
      "Epoch[3/15], Step [290/469], Reconst Loss: 12029.3457, KL Div: 3201.5845\n",
      "Epoch[3/15], Step [300/469], Reconst Loss: 11657.3389, KL Div: 3086.0437\n",
      "Epoch[3/15], Step [310/469], Reconst Loss: 11570.6328, KL Div: 3121.7651\n",
      "Epoch[3/15], Step [320/469], Reconst Loss: 11508.0430, KL Div: 3056.6558\n",
      "Epoch[3/15], Step [330/469], Reconst Loss: 11467.7314, KL Div: 3084.4023\n",
      "Epoch[3/15], Step [340/469], Reconst Loss: 11223.3740, KL Div: 3099.8782\n",
      "Epoch[3/15], Step [350/469], Reconst Loss: 11285.4277, KL Div: 3089.9790\n",
      "Epoch[3/15], Step [360/469], Reconst Loss: 11818.2324, KL Div: 3082.4961\n",
      "Epoch[3/15], Step [370/469], Reconst Loss: 11475.7139, KL Div: 3183.5898\n",
      "Epoch[3/15], Step [380/469], Reconst Loss: 11457.4160, KL Div: 3136.9153\n",
      "Epoch[3/15], Step [390/469], Reconst Loss: 11424.0176, KL Div: 3092.5588\n",
      "Epoch[3/15], Step [400/469], Reconst Loss: 11729.3662, KL Div: 3130.3896\n",
      "Epoch[3/15], Step [410/469], Reconst Loss: 11651.4004, KL Div: 3173.7671\n",
      "Epoch[3/15], Step [420/469], Reconst Loss: 11263.0967, KL Div: 3101.4165\n",
      "Epoch[3/15], Step [430/469], Reconst Loss: 12007.5078, KL Div: 3187.8711\n",
      "Epoch[3/15], Step [440/469], Reconst Loss: 11315.5703, KL Div: 3142.9692\n",
      "Epoch[3/15], Step [450/469], Reconst Loss: 11417.3115, KL Div: 3090.4280\n",
      "Epoch[3/15], Step [460/469], Reconst Loss: 11354.4844, KL Div: 3137.3293\n",
      "Epoch[4/15], Step [10/469], Reconst Loss: 10975.1641, KL Div: 3121.1689\n",
      "Epoch[4/15], Step [20/469], Reconst Loss: 10991.3730, KL Div: 3106.9175\n",
      "Epoch[4/15], Step [30/469], Reconst Loss: 11146.9834, KL Div: 3279.2683\n",
      "Epoch[4/15], Step [40/469], Reconst Loss: 11645.3477, KL Div: 3234.1338\n",
      "Epoch[4/15], Step [50/469], Reconst Loss: 11264.6768, KL Div: 3102.6772\n",
      "Epoch[4/15], Step [60/469], Reconst Loss: 11148.9980, KL Div: 3154.5569\n",
      "Epoch[4/15], Step [70/469], Reconst Loss: 11284.7979, KL Div: 3123.6514\n",
      "Epoch[4/15], Step [80/469], Reconst Loss: 11810.8926, KL Div: 3233.9009\n",
      "Epoch[4/15], Step [90/469], Reconst Loss: 11145.6426, KL Div: 3129.9470\n",
      "Epoch[4/15], Step [100/469], Reconst Loss: 10731.2383, KL Div: 3244.2732\n",
      "Epoch[4/15], Step [110/469], Reconst Loss: 11142.6230, KL Div: 3150.5679\n",
      "Epoch[4/15], Step [120/469], Reconst Loss: 10863.4385, KL Div: 3089.5615\n",
      "Epoch[4/15], Step [130/469], Reconst Loss: 11128.0859, KL Div: 3115.4683\n",
      "Epoch[4/15], Step [140/469], Reconst Loss: 11377.4375, KL Div: 3210.6558\n",
      "Epoch[4/15], Step [150/469], Reconst Loss: 11517.1328, KL Div: 3146.8276\n",
      "Epoch[4/15], Step [160/469], Reconst Loss: 10986.0342, KL Div: 3068.6545\n",
      "Epoch[4/15], Step [170/469], Reconst Loss: 10818.6309, KL Div: 3092.8210\n",
      "Epoch[4/15], Step [180/469], Reconst Loss: 11804.7373, KL Div: 3142.2939\n",
      "Epoch[4/15], Step [190/469], Reconst Loss: 10820.6299, KL Div: 3116.9036\n",
      "Epoch[4/15], Step [200/469], Reconst Loss: 11129.5977, KL Div: 3175.8206\n",
      "Epoch[4/15], Step [210/469], Reconst Loss: 10757.5625, KL Div: 3136.8743\n",
      "Epoch[4/15], Step [220/469], Reconst Loss: 10830.7852, KL Div: 3135.4146\n",
      "Epoch[4/15], Step [230/469], Reconst Loss: 10748.8750, KL Div: 3182.5371\n",
      "Epoch[4/15], Step [240/469], Reconst Loss: 10759.7686, KL Div: 3138.7373\n",
      "Epoch[4/15], Step [250/469], Reconst Loss: 11239.4414, KL Div: 3206.7070\n",
      "Epoch[4/15], Step [260/469], Reconst Loss: 11485.0000, KL Div: 3065.8335\n",
      "Epoch[4/15], Step [270/469], Reconst Loss: 10377.8281, KL Div: 3214.7690\n",
      "Epoch[4/15], Step [280/469], Reconst Loss: 11672.4404, KL Div: 3104.0698\n",
      "Epoch[4/15], Step [290/469], Reconst Loss: 10881.9385, KL Div: 3144.7935\n",
      "Epoch[4/15], Step [300/469], Reconst Loss: 11214.7715, KL Div: 3159.7605\n",
      "Epoch[4/15], Step [310/469], Reconst Loss: 10670.1504, KL Div: 3109.3784\n",
      "Epoch[4/15], Step [320/469], Reconst Loss: 11476.7314, KL Div: 3212.9570\n",
      "Epoch[4/15], Step [330/469], Reconst Loss: 10820.6914, KL Div: 3114.5801\n",
      "Epoch[4/15], Step [340/469], Reconst Loss: 10769.3867, KL Div: 3039.5649\n",
      "Epoch[4/15], Step [350/469], Reconst Loss: 11098.7402, KL Div: 3184.4512\n",
      "Epoch[4/15], Step [360/469], Reconst Loss: 10648.2920, KL Div: 3085.5991\n",
      "Epoch[4/15], Step [370/469], Reconst Loss: 10945.4219, KL Div: 3278.7090\n",
      "Epoch[4/15], Step [380/469], Reconst Loss: 11333.0068, KL Div: 3115.1284\n",
      "Epoch[4/15], Step [390/469], Reconst Loss: 11650.4238, KL Div: 3295.3833\n",
      "Epoch[4/15], Step [400/469], Reconst Loss: 11068.7568, KL Div: 3173.4097\n",
      "Epoch[4/15], Step [410/469], Reconst Loss: 10956.9268, KL Div: 3140.8115\n",
      "Epoch[4/15], Step [420/469], Reconst Loss: 10640.1641, KL Div: 3145.8857\n",
      "Epoch[4/15], Step [430/469], Reconst Loss: 11022.8242, KL Div: 3143.5356\n",
      "Epoch[4/15], Step [440/469], Reconst Loss: 10731.3838, KL Div: 3153.5557\n",
      "Epoch[4/15], Step [450/469], Reconst Loss: 10990.3828, KL Div: 3187.9106\n",
      "Epoch[4/15], Step [460/469], Reconst Loss: 10539.7559, KL Div: 3153.8455\n",
      "Epoch[5/15], Step [10/469], Reconst Loss: 11230.9980, KL Div: 3235.8345\n",
      "Epoch[5/15], Step [20/469], Reconst Loss: 10728.9912, KL Div: 3075.4961\n",
      "Epoch[5/15], Step [30/469], Reconst Loss: 10691.8359, KL Div: 3217.7424\n",
      "Epoch[5/15], Step [40/469], Reconst Loss: 11054.4746, KL Div: 3261.4072\n",
      "Epoch[5/15], Step [50/469], Reconst Loss: 11413.5293, KL Div: 3254.9409\n",
      "Epoch[5/15], Step [60/469], Reconst Loss: 10778.1758, KL Div: 3225.7622\n",
      "Epoch[5/15], Step [70/469], Reconst Loss: 11051.9277, KL Div: 3202.3247\n",
      "Epoch[5/15], Step [80/469], Reconst Loss: 10502.8340, KL Div: 3107.2925\n",
      "Epoch[5/15], Step [90/469], Reconst Loss: 11284.7129, KL Div: 3239.9287\n",
      "Epoch[5/15], Step [100/469], Reconst Loss: 11128.7021, KL Div: 3147.9229\n",
      "Epoch[5/15], Step [110/469], Reconst Loss: 10483.3506, KL Div: 3139.6819\n",
      "Epoch[5/15], Step [120/469], Reconst Loss: 10340.0811, KL Div: 3219.6035\n",
      "Epoch[5/15], Step [130/469], Reconst Loss: 10963.9717, KL Div: 3049.9937\n",
      "Epoch[5/15], Step [140/469], Reconst Loss: 10931.7637, KL Div: 3227.8308\n",
      "Epoch[5/15], Step [150/469], Reconst Loss: 10970.5703, KL Div: 3232.3931\n",
      "Epoch[5/15], Step [160/469], Reconst Loss: 11080.7871, KL Div: 3232.2002\n",
      "Epoch[5/15], Step [170/469], Reconst Loss: 10976.1650, KL Div: 3230.2400\n",
      "Epoch[5/15], Step [180/469], Reconst Loss: 11090.4883, KL Div: 3165.9932\n",
      "Epoch[5/15], Step [190/469], Reconst Loss: 11273.7461, KL Div: 3267.4966\n",
      "Epoch[5/15], Step [200/469], Reconst Loss: 10618.3975, KL Div: 3109.4570\n",
      "Epoch[5/15], Step [210/469], Reconst Loss: 10710.0684, KL Div: 3121.4890\n",
      "Epoch[5/15], Step [220/469], Reconst Loss: 10859.2129, KL Div: 3248.9287\n",
      "Epoch[5/15], Step [230/469], Reconst Loss: 10478.1328, KL Div: 3088.1467\n",
      "Epoch[5/15], Step [240/469], Reconst Loss: 11035.0635, KL Div: 3175.5830\n",
      "Epoch[5/15], Step [250/469], Reconst Loss: 10975.8945, KL Div: 3131.2483\n",
      "Epoch[5/15], Step [260/469], Reconst Loss: 10304.0420, KL Div: 3110.1206\n",
      "Epoch[5/15], Step [270/469], Reconst Loss: 11206.6943, KL Div: 3266.4062\n",
      "Epoch[5/15], Step [280/469], Reconst Loss: 10897.6357, KL Div: 3220.9731\n",
      "Epoch[5/15], Step [290/469], Reconst Loss: 10673.2500, KL Div: 3250.7119\n",
      "Epoch[5/15], Step [300/469], Reconst Loss: 11477.3945, KL Div: 3144.0964\n",
      "Epoch[5/15], Step [310/469], Reconst Loss: 10678.3965, KL Div: 3164.3906\n",
      "Epoch[5/15], Step [320/469], Reconst Loss: 10859.5850, KL Div: 3146.1938\n",
      "Epoch[5/15], Step [330/469], Reconst Loss: 10744.5840, KL Div: 3198.7500\n",
      "Epoch[5/15], Step [340/469], Reconst Loss: 10889.7529, KL Div: 3189.9177\n",
      "Epoch[5/15], Step [350/469], Reconst Loss: 10812.9580, KL Div: 3264.6655\n",
      "Epoch[5/15], Step [360/469], Reconst Loss: 10430.8730, KL Div: 3174.4712\n",
      "Epoch[5/15], Step [370/469], Reconst Loss: 10993.9492, KL Div: 3238.9756\n",
      "Epoch[5/15], Step [380/469], Reconst Loss: 10997.0049, KL Div: 3124.5012\n",
      "Epoch[5/15], Step [390/469], Reconst Loss: 11021.9941, KL Div: 3229.2266\n",
      "Epoch[5/15], Step [400/469], Reconst Loss: 10851.8379, KL Div: 3279.4409\n",
      "Epoch[5/15], Step [410/469], Reconst Loss: 10855.1084, KL Div: 3294.8950\n",
      "Epoch[5/15], Step [420/469], Reconst Loss: 10596.5566, KL Div: 3164.5378\n",
      "Epoch[5/15], Step [430/469], Reconst Loss: 11025.6152, KL Div: 3244.0610\n",
      "Epoch[5/15], Step [440/469], Reconst Loss: 10626.7295, KL Div: 3124.7544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5/15], Step [450/469], Reconst Loss: 10269.6680, KL Div: 3262.7031\n",
      "Epoch[5/15], Step [460/469], Reconst Loss: 10856.7510, KL Div: 3211.4934\n",
      "Epoch[6/15], Step [10/469], Reconst Loss: 10605.3652, KL Div: 3067.2959\n",
      "Epoch[6/15], Step [20/469], Reconst Loss: 10681.3408, KL Div: 3253.9158\n",
      "Epoch[6/15], Step [30/469], Reconst Loss: 11003.3672, KL Div: 3251.9829\n",
      "Epoch[6/15], Step [40/469], Reconst Loss: 10562.5146, KL Div: 3280.1973\n",
      "Epoch[6/15], Step [50/469], Reconst Loss: 10597.6934, KL Div: 3212.3723\n",
      "Epoch[6/15], Step [60/469], Reconst Loss: 10827.9902, KL Div: 3145.1206\n",
      "Epoch[6/15], Step [70/469], Reconst Loss: 10770.3965, KL Div: 3219.1982\n",
      "Epoch[6/15], Step [80/469], Reconst Loss: 10681.6035, KL Div: 3099.6875\n",
      "Epoch[6/15], Step [90/469], Reconst Loss: 10953.9717, KL Div: 3238.1262\n",
      "Epoch[6/15], Step [100/469], Reconst Loss: 10937.5527, KL Div: 3342.9473\n",
      "Epoch[6/15], Step [110/469], Reconst Loss: 10658.8027, KL Div: 3300.8662\n",
      "Epoch[6/15], Step [120/469], Reconst Loss: 11305.5547, KL Div: 3262.4014\n",
      "Epoch[6/15], Step [130/469], Reconst Loss: 10930.5879, KL Div: 3260.1458\n",
      "Epoch[6/15], Step [140/469], Reconst Loss: 10270.7559, KL Div: 3084.7861\n",
      "Epoch[6/15], Step [150/469], Reconst Loss: 10868.3604, KL Div: 3274.2876\n",
      "Epoch[6/15], Step [160/469], Reconst Loss: 10704.7139, KL Div: 3117.1208\n",
      "Epoch[6/15], Step [170/469], Reconst Loss: 11079.4043, KL Div: 3184.5732\n",
      "Epoch[6/15], Step [180/469], Reconst Loss: 10892.6211, KL Div: 3257.4731\n",
      "Epoch[6/15], Step [190/469], Reconst Loss: 10799.2139, KL Div: 3237.8000\n",
      "Epoch[6/15], Step [200/469], Reconst Loss: 10896.8887, KL Div: 3298.4263\n",
      "Epoch[6/15], Step [210/469], Reconst Loss: 11059.4844, KL Div: 3168.6262\n",
      "Epoch[6/15], Step [220/469], Reconst Loss: 10822.4473, KL Div: 3268.4326\n",
      "Epoch[6/15], Step [230/469], Reconst Loss: 10888.9258, KL Div: 3125.7800\n",
      "Epoch[6/15], Step [240/469], Reconst Loss: 10796.3193, KL Div: 3215.3088\n",
      "Epoch[6/15], Step [250/469], Reconst Loss: 11057.1680, KL Div: 3183.1909\n",
      "Epoch[6/15], Step [260/469], Reconst Loss: 10477.3555, KL Div: 3201.7266\n",
      "Epoch[6/15], Step [270/469], Reconst Loss: 10246.0713, KL Div: 3145.3005\n",
      "Epoch[6/15], Step [280/469], Reconst Loss: 10893.6484, KL Div: 3141.0166\n",
      "Epoch[6/15], Step [290/469], Reconst Loss: 10871.1504, KL Div: 3292.7585\n",
      "Epoch[6/15], Step [300/469], Reconst Loss: 10922.2832, KL Div: 3186.2959\n",
      "Epoch[6/15], Step [310/469], Reconst Loss: 10423.2412, KL Div: 3157.5591\n",
      "Epoch[6/15], Step [320/469], Reconst Loss: 10936.2188, KL Div: 3192.9771\n",
      "Epoch[6/15], Step [330/469], Reconst Loss: 11017.0830, KL Div: 3238.4299\n",
      "Epoch[6/15], Step [340/469], Reconst Loss: 10942.6973, KL Div: 3167.6653\n",
      "Epoch[6/15], Step [350/469], Reconst Loss: 10665.1875, KL Div: 3278.1333\n",
      "Epoch[6/15], Step [360/469], Reconst Loss: 10549.6582, KL Div: 3180.1230\n",
      "Epoch[6/15], Step [370/469], Reconst Loss: 10393.4971, KL Div: 3199.9580\n",
      "Epoch[6/15], Step [380/469], Reconst Loss: 10491.4521, KL Div: 3197.3779\n",
      "Epoch[6/15], Step [390/469], Reconst Loss: 10600.8740, KL Div: 3127.9902\n",
      "Epoch[6/15], Step [400/469], Reconst Loss: 10417.1445, KL Div: 3143.7666\n",
      "Epoch[6/15], Step [410/469], Reconst Loss: 10535.3252, KL Div: 3209.2646\n",
      "Epoch[6/15], Step [420/469], Reconst Loss: 10742.2852, KL Div: 3180.4775\n",
      "Epoch[6/15], Step [430/469], Reconst Loss: 10549.9580, KL Div: 3135.7480\n",
      "Epoch[6/15], Step [440/469], Reconst Loss: 10607.4824, KL Div: 3248.4426\n",
      "Epoch[6/15], Step [450/469], Reconst Loss: 10154.0693, KL Div: 3138.9902\n",
      "Epoch[6/15], Step [460/469], Reconst Loss: 10748.9512, KL Div: 3252.6343\n",
      "Epoch[7/15], Step [10/469], Reconst Loss: 10974.9180, KL Div: 3237.1821\n",
      "Epoch[7/15], Step [20/469], Reconst Loss: 10640.2510, KL Div: 3275.9561\n",
      "Epoch[7/15], Step [30/469], Reconst Loss: 10859.0508, KL Div: 3254.6523\n",
      "Epoch[7/15], Step [40/469], Reconst Loss: 10896.7803, KL Div: 3190.4038\n",
      "Epoch[7/15], Step [50/469], Reconst Loss: 10989.3926, KL Div: 3387.5742\n",
      "Epoch[7/15], Step [60/469], Reconst Loss: 11211.9238, KL Div: 3223.7173\n",
      "Epoch[7/15], Step [70/469], Reconst Loss: 10537.4082, KL Div: 3159.4966\n",
      "Epoch[7/15], Step [80/469], Reconst Loss: 10389.8867, KL Div: 3160.1772\n",
      "Epoch[7/15], Step [90/469], Reconst Loss: 10284.8516, KL Div: 3142.2729\n",
      "Epoch[7/15], Step [100/469], Reconst Loss: 11124.6992, KL Div: 3305.3794\n",
      "Epoch[7/15], Step [110/469], Reconst Loss: 10268.6494, KL Div: 3126.3958\n",
      "Epoch[7/15], Step [120/469], Reconst Loss: 10062.1543, KL Div: 3199.8982\n",
      "Epoch[7/15], Step [130/469], Reconst Loss: 10817.8389, KL Div: 3170.5054\n",
      "Epoch[7/15], Step [140/469], Reconst Loss: 10730.1904, KL Div: 3208.8589\n",
      "Epoch[7/15], Step [150/469], Reconst Loss: 10338.7500, KL Div: 3136.6733\n",
      "Epoch[7/15], Step [160/469], Reconst Loss: 10689.5957, KL Div: 3281.5144\n",
      "Epoch[7/15], Step [170/469], Reconst Loss: 10259.4248, KL Div: 3183.0928\n",
      "Epoch[7/15], Step [180/469], Reconst Loss: 10883.8438, KL Div: 3256.6499\n",
      "Epoch[7/15], Step [190/469], Reconst Loss: 10580.4697, KL Div: 3280.6978\n",
      "Epoch[7/15], Step [200/469], Reconst Loss: 10301.9316, KL Div: 3103.9275\n",
      "Epoch[7/15], Step [210/469], Reconst Loss: 10668.9619, KL Div: 3265.5920\n",
      "Epoch[7/15], Step [220/469], Reconst Loss: 10806.1172, KL Div: 3191.9312\n",
      "Epoch[7/15], Step [230/469], Reconst Loss: 11054.6270, KL Div: 3181.4807\n",
      "Epoch[7/15], Step [240/469], Reconst Loss: 10922.4951, KL Div: 3261.3127\n",
      "Epoch[7/15], Step [250/469], Reconst Loss: 10605.1465, KL Div: 3294.0164\n",
      "Epoch[7/15], Step [260/469], Reconst Loss: 10343.1895, KL Div: 3206.6536\n",
      "Epoch[7/15], Step [270/469], Reconst Loss: 10997.0420, KL Div: 3252.8198\n",
      "Epoch[7/15], Step [280/469], Reconst Loss: 10483.9023, KL Div: 3205.2427\n",
      "Epoch[7/15], Step [290/469], Reconst Loss: 10685.8477, KL Div: 3256.6584\n",
      "Epoch[7/15], Step [300/469], Reconst Loss: 10220.0928, KL Div: 3263.0820\n",
      "Epoch[7/15], Step [310/469], Reconst Loss: 10793.9082, KL Div: 3169.8188\n",
      "Epoch[7/15], Step [320/469], Reconst Loss: 10761.7090, KL Div: 3307.1895\n",
      "Epoch[7/15], Step [330/469], Reconst Loss: 10569.5273, KL Div: 3137.2629\n",
      "Epoch[7/15], Step [340/469], Reconst Loss: 10635.2803, KL Div: 3319.7832\n",
      "Epoch[7/15], Step [350/469], Reconst Loss: 11144.7217, KL Div: 3204.9773\n",
      "Epoch[7/15], Step [360/469], Reconst Loss: 10538.6953, KL Div: 3376.3232\n",
      "Epoch[7/15], Step [370/469], Reconst Loss: 10503.5664, KL Div: 3209.0083\n",
      "Epoch[7/15], Step [380/469], Reconst Loss: 10846.6348, KL Div: 3199.0640\n",
      "Epoch[7/15], Step [390/469], Reconst Loss: 10673.0312, KL Div: 3218.0322\n",
      "Epoch[7/15], Step [400/469], Reconst Loss: 10117.9707, KL Div: 3258.5410\n",
      "Epoch[7/15], Step [410/469], Reconst Loss: 10300.4707, KL Div: 3166.7219\n",
      "Epoch[7/15], Step [420/469], Reconst Loss: 10950.1035, KL Div: 3312.1694\n",
      "Epoch[7/15], Step [430/469], Reconst Loss: 10422.7588, KL Div: 3168.3730\n",
      "Epoch[7/15], Step [440/469], Reconst Loss: 10591.6387, KL Div: 3285.1099\n",
      "Epoch[7/15], Step [450/469], Reconst Loss: 10627.6582, KL Div: 3216.3188\n",
      "Epoch[7/15], Step [460/469], Reconst Loss: 10526.0469, KL Div: 3230.0161\n",
      "Epoch[8/15], Step [10/469], Reconst Loss: 10279.4492, KL Div: 3213.8062\n",
      "Epoch[8/15], Step [20/469], Reconst Loss: 10365.6875, KL Div: 3216.7842\n",
      "Epoch[8/15], Step [30/469], Reconst Loss: 10413.0078, KL Div: 3232.2095\n",
      "Epoch[8/15], Step [40/469], Reconst Loss: 10643.6270, KL Div: 3251.0591\n",
      "Epoch[8/15], Step [50/469], Reconst Loss: 10118.0322, KL Div: 3244.4688\n",
      "Epoch[8/15], Step [60/469], Reconst Loss: 10218.2275, KL Div: 3175.6028\n",
      "Epoch[8/15], Step [70/469], Reconst Loss: 10269.1240, KL Div: 3224.9575\n",
      "Epoch[8/15], Step [80/469], Reconst Loss: 10423.7051, KL Div: 3200.2310\n",
      "Epoch[8/15], Step [90/469], Reconst Loss: 10270.2891, KL Div: 3142.3364\n",
      "Epoch[8/15], Step [100/469], Reconst Loss: 10915.4531, KL Div: 3242.4768\n",
      "Epoch[8/15], Step [110/469], Reconst Loss: 10359.0479, KL Div: 3236.8276\n",
      "Epoch[8/15], Step [120/469], Reconst Loss: 9847.0801, KL Div: 3134.4004\n",
      "Epoch[8/15], Step [130/469], Reconst Loss: 10475.4727, KL Div: 3217.0823\n",
      "Epoch[8/15], Step [140/469], Reconst Loss: 10727.0420, KL Div: 3212.7275\n",
      "Epoch[8/15], Step [150/469], Reconst Loss: 10236.9307, KL Div: 3176.8408\n",
      "Epoch[8/15], Step [160/469], Reconst Loss: 10815.4473, KL Div: 3188.3120\n",
      "Epoch[8/15], Step [170/469], Reconst Loss: 10593.6572, KL Div: 3284.9580\n",
      "Epoch[8/15], Step [180/469], Reconst Loss: 10251.5732, KL Div: 3219.4858\n",
      "Epoch[8/15], Step [190/469], Reconst Loss: 10278.2305, KL Div: 3211.0815\n",
      "Epoch[8/15], Step [200/469], Reconst Loss: 10300.2578, KL Div: 3041.1064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8/15], Step [210/469], Reconst Loss: 10223.4180, KL Div: 3145.8887\n",
      "Epoch[8/15], Step [220/469], Reconst Loss: 10435.1963, KL Div: 3190.4531\n",
      "Epoch[8/15], Step [230/469], Reconst Loss: 10607.6113, KL Div: 3269.5840\n",
      "Epoch[8/15], Step [240/469], Reconst Loss: 10774.9365, KL Div: 3278.8530\n",
      "Epoch[8/15], Step [250/469], Reconst Loss: 10547.1064, KL Div: 3196.9976\n",
      "Epoch[8/15], Step [260/469], Reconst Loss: 10654.3193, KL Div: 3302.2734\n",
      "Epoch[8/15], Step [270/469], Reconst Loss: 10829.7686, KL Div: 3210.8096\n",
      "Epoch[8/15], Step [280/469], Reconst Loss: 10657.5156, KL Div: 3170.4146\n",
      "Epoch[8/15], Step [290/469], Reconst Loss: 10590.9277, KL Div: 3230.7173\n",
      "Epoch[8/15], Step [300/469], Reconst Loss: 10153.7168, KL Div: 3153.4141\n",
      "Epoch[8/15], Step [310/469], Reconst Loss: 10239.4766, KL Div: 3212.6157\n",
      "Epoch[8/15], Step [320/469], Reconst Loss: 10764.2900, KL Div: 3394.9800\n",
      "Epoch[8/15], Step [330/469], Reconst Loss: 10616.6768, KL Div: 3152.8242\n",
      "Epoch[8/15], Step [340/469], Reconst Loss: 10405.5107, KL Div: 3235.4370\n",
      "Epoch[8/15], Step [350/469], Reconst Loss: 10657.0703, KL Div: 3246.9346\n",
      "Epoch[8/15], Step [360/469], Reconst Loss: 10350.2266, KL Div: 3227.6772\n",
      "Epoch[8/15], Step [370/469], Reconst Loss: 10739.4912, KL Div: 3128.8726\n",
      "Epoch[8/15], Step [380/469], Reconst Loss: 10166.6543, KL Div: 3191.3232\n",
      "Epoch[8/15], Step [390/469], Reconst Loss: 10413.6631, KL Div: 3255.4988\n",
      "Epoch[8/15], Step [400/469], Reconst Loss: 10324.9414, KL Div: 3280.9399\n",
      "Epoch[8/15], Step [410/469], Reconst Loss: 10695.3711, KL Div: 3191.4897\n",
      "Epoch[8/15], Step [420/469], Reconst Loss: 10376.8457, KL Div: 3159.7148\n",
      "Epoch[8/15], Step [430/469], Reconst Loss: 10513.0889, KL Div: 3292.2485\n",
      "Epoch[8/15], Step [440/469], Reconst Loss: 10872.2539, KL Div: 3198.4431\n",
      "Epoch[8/15], Step [450/469], Reconst Loss: 10633.0508, KL Div: 3245.8735\n",
      "Epoch[8/15], Step [460/469], Reconst Loss: 10237.1016, KL Div: 3249.6816\n",
      "Epoch[9/15], Step [10/469], Reconst Loss: 10491.5020, KL Div: 3185.3167\n",
      "Epoch[9/15], Step [20/469], Reconst Loss: 10311.0176, KL Div: 3303.4658\n",
      "Epoch[9/15], Step [30/469], Reconst Loss: 10274.7490, KL Div: 3178.1753\n",
      "Epoch[9/15], Step [40/469], Reconst Loss: 10045.7285, KL Div: 3124.8220\n",
      "Epoch[9/15], Step [50/469], Reconst Loss: 10007.8398, KL Div: 3181.1653\n",
      "Epoch[9/15], Step [60/469], Reconst Loss: 10546.9141, KL Div: 3221.2607\n",
      "Epoch[9/15], Step [70/469], Reconst Loss: 10822.2754, KL Div: 3283.7791\n",
      "Epoch[9/15], Step [80/469], Reconst Loss: 10516.4766, KL Div: 3257.9348\n",
      "Epoch[9/15], Step [90/469], Reconst Loss: 10552.0029, KL Div: 3178.6235\n",
      "Epoch[9/15], Step [100/469], Reconst Loss: 10362.3750, KL Div: 3212.1396\n",
      "Epoch[9/15], Step [110/469], Reconst Loss: 10043.4990, KL Div: 3170.4495\n",
      "Epoch[9/15], Step [120/469], Reconst Loss: 10248.5137, KL Div: 3159.2583\n",
      "Epoch[9/15], Step [130/469], Reconst Loss: 10383.0254, KL Div: 3158.5063\n",
      "Epoch[9/15], Step [140/469], Reconst Loss: 10630.0557, KL Div: 3286.9990\n",
      "Epoch[9/15], Step [150/469], Reconst Loss: 10641.3672, KL Div: 3185.0398\n",
      "Epoch[9/15], Step [160/469], Reconst Loss: 10278.5312, KL Div: 3330.6638\n",
      "Epoch[9/15], Step [170/469], Reconst Loss: 10219.1748, KL Div: 3264.3369\n",
      "Epoch[9/15], Step [180/469], Reconst Loss: 10434.5391, KL Div: 3113.6438\n",
      "Epoch[9/15], Step [190/469], Reconst Loss: 10986.0215, KL Div: 3242.0315\n",
      "Epoch[9/15], Step [200/469], Reconst Loss: 9918.0967, KL Div: 3199.3308\n",
      "Epoch[9/15], Step [210/469], Reconst Loss: 10547.5557, KL Div: 3340.0532\n",
      "Epoch[9/15], Step [220/469], Reconst Loss: 10253.4980, KL Div: 3217.4626\n",
      "Epoch[9/15], Step [230/469], Reconst Loss: 10071.0117, KL Div: 3270.5234\n",
      "Epoch[9/15], Step [240/469], Reconst Loss: 10577.9492, KL Div: 3381.0847\n",
      "Epoch[9/15], Step [250/469], Reconst Loss: 10250.9307, KL Div: 3235.6252\n",
      "Epoch[9/15], Step [260/469], Reconst Loss: 10280.9375, KL Div: 3205.5508\n",
      "Epoch[9/15], Step [270/469], Reconst Loss: 10760.1445, KL Div: 3262.2314\n",
      "Epoch[9/15], Step [280/469], Reconst Loss: 10406.2578, KL Div: 3219.1812\n",
      "Epoch[9/15], Step [290/469], Reconst Loss: 10392.8994, KL Div: 3221.3604\n",
      "Epoch[9/15], Step [300/469], Reconst Loss: 10470.9697, KL Div: 3179.9302\n",
      "Epoch[9/15], Step [310/469], Reconst Loss: 10941.2549, KL Div: 3293.1709\n",
      "Epoch[9/15], Step [320/469], Reconst Loss: 10385.5547, KL Div: 3260.3550\n",
      "Epoch[9/15], Step [330/469], Reconst Loss: 10179.5127, KL Div: 3048.9143\n",
      "Epoch[9/15], Step [340/469], Reconst Loss: 11130.6133, KL Div: 3336.8179\n",
      "Epoch[9/15], Step [350/469], Reconst Loss: 10474.5244, KL Div: 3236.8989\n",
      "Epoch[9/15], Step [360/469], Reconst Loss: 10614.2139, KL Div: 3333.0508\n",
      "Epoch[9/15], Step [370/469], Reconst Loss: 10629.2246, KL Div: 3214.6021\n",
      "Epoch[9/15], Step [380/469], Reconst Loss: 9952.1221, KL Div: 3181.6689\n",
      "Epoch[9/15], Step [390/469], Reconst Loss: 10496.6787, KL Div: 3194.5718\n",
      "Epoch[9/15], Step [400/469], Reconst Loss: 10588.7764, KL Div: 3214.3086\n",
      "Epoch[9/15], Step [410/469], Reconst Loss: 10339.3535, KL Div: 3223.0481\n",
      "Epoch[9/15], Step [420/469], Reconst Loss: 10256.5498, KL Div: 3259.1460\n",
      "Epoch[9/15], Step [430/469], Reconst Loss: 10503.4863, KL Div: 3117.7041\n",
      "Epoch[9/15], Step [440/469], Reconst Loss: 10332.7520, KL Div: 3192.9531\n",
      "Epoch[9/15], Step [450/469], Reconst Loss: 10261.9170, KL Div: 3241.9148\n",
      "Epoch[9/15], Step [460/469], Reconst Loss: 10281.4883, KL Div: 3233.4775\n",
      "Epoch[10/15], Step [10/469], Reconst Loss: 10128.8027, KL Div: 3199.0825\n",
      "Epoch[10/15], Step [20/469], Reconst Loss: 10399.4785, KL Div: 3307.3054\n",
      "Epoch[10/15], Step [30/469], Reconst Loss: 9904.5840, KL Div: 3239.4529\n",
      "Epoch[10/15], Step [40/469], Reconst Loss: 10486.3652, KL Div: 3147.3203\n",
      "Epoch[10/15], Step [50/469], Reconst Loss: 10020.5752, KL Div: 3133.8931\n",
      "Epoch[10/15], Step [60/469], Reconst Loss: 10843.3047, KL Div: 3331.1750\n",
      "Epoch[10/15], Step [70/469], Reconst Loss: 10427.2471, KL Div: 3237.1477\n",
      "Epoch[10/15], Step [80/469], Reconst Loss: 10278.5908, KL Div: 3178.5283\n",
      "Epoch[10/15], Step [90/469], Reconst Loss: 10340.2754, KL Div: 3300.9731\n",
      "Epoch[10/15], Step [100/469], Reconst Loss: 10825.6270, KL Div: 3181.3923\n",
      "Epoch[10/15], Step [110/469], Reconst Loss: 9747.0352, KL Div: 3192.3569\n",
      "Epoch[10/15], Step [120/469], Reconst Loss: 10659.8594, KL Div: 3310.8506\n",
      "Epoch[10/15], Step [130/469], Reconst Loss: 10294.6973, KL Div: 3157.7961\n",
      "Epoch[10/15], Step [140/469], Reconst Loss: 9922.8330, KL Div: 3273.6936\n",
      "Epoch[10/15], Step [150/469], Reconst Loss: 10307.4385, KL Div: 3215.8862\n",
      "Epoch[10/15], Step [160/469], Reconst Loss: 9912.1338, KL Div: 3179.7383\n",
      "Epoch[10/15], Step [170/469], Reconst Loss: 10597.4609, KL Div: 3208.3618\n",
      "Epoch[10/15], Step [180/469], Reconst Loss: 10281.7959, KL Div: 3139.2861\n",
      "Epoch[10/15], Step [190/469], Reconst Loss: 10536.8242, KL Div: 3253.5901\n",
      "Epoch[10/15], Step [200/469], Reconst Loss: 10863.7295, KL Div: 3244.0825\n",
      "Epoch[10/15], Step [210/469], Reconst Loss: 9957.6787, KL Div: 3014.6885\n",
      "Epoch[10/15], Step [220/469], Reconst Loss: 10496.7109, KL Div: 3290.2104\n",
      "Epoch[10/15], Step [230/469], Reconst Loss: 10792.9619, KL Div: 3300.8396\n",
      "Epoch[10/15], Step [240/469], Reconst Loss: 10663.8857, KL Div: 3272.6221\n",
      "Epoch[10/15], Step [250/469], Reconst Loss: 10131.4531, KL Div: 3084.0032\n",
      "Epoch[10/15], Step [260/469], Reconst Loss: 9766.8896, KL Div: 3327.6914\n",
      "Epoch[10/15], Step [270/469], Reconst Loss: 10042.3574, KL Div: 3199.5125\n",
      "Epoch[10/15], Step [280/469], Reconst Loss: 10723.5703, KL Div: 3226.8408\n",
      "Epoch[10/15], Step [290/469], Reconst Loss: 10711.1572, KL Div: 3291.3252\n",
      "Epoch[10/15], Step [300/469], Reconst Loss: 10417.4766, KL Div: 3256.1892\n",
      "Epoch[10/15], Step [310/469], Reconst Loss: 10116.3008, KL Div: 3260.3367\n",
      "Epoch[10/15], Step [320/469], Reconst Loss: 10533.1641, KL Div: 3345.1709\n",
      "Epoch[10/15], Step [330/469], Reconst Loss: 10240.3584, KL Div: 3186.4146\n",
      "Epoch[10/15], Step [340/469], Reconst Loss: 10410.6582, KL Div: 3234.0042\n",
      "Epoch[10/15], Step [350/469], Reconst Loss: 10642.2305, KL Div: 3198.7932\n",
      "Epoch[10/15], Step [360/469], Reconst Loss: 9929.8691, KL Div: 3096.4214\n",
      "Epoch[10/15], Step [370/469], Reconst Loss: 10800.7881, KL Div: 3409.0796\n",
      "Epoch[10/15], Step [380/469], Reconst Loss: 10439.3730, KL Div: 3156.5325\n",
      "Epoch[10/15], Step [390/469], Reconst Loss: 10182.2100, KL Div: 3141.8943\n",
      "Epoch[10/15], Step [400/469], Reconst Loss: 10068.2764, KL Div: 3264.4358\n",
      "Epoch[10/15], Step [410/469], Reconst Loss: 10330.7305, KL Div: 3261.0356\n",
      "Epoch[10/15], Step [420/469], Reconst Loss: 10460.5781, KL Div: 3185.9895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/15], Step [430/469], Reconst Loss: 10603.2900, KL Div: 3212.3818\n",
      "Epoch[10/15], Step [440/469], Reconst Loss: 9917.1660, KL Div: 3141.9326\n",
      "Epoch[10/15], Step [450/469], Reconst Loss: 10478.7051, KL Div: 3236.8784\n",
      "Epoch[10/15], Step [460/469], Reconst Loss: 9953.6016, KL Div: 3262.5095\n",
      "Epoch[11/15], Step [10/469], Reconst Loss: 10306.1475, KL Div: 3179.4863\n",
      "Epoch[11/15], Step [20/469], Reconst Loss: 10404.5166, KL Div: 3157.5874\n",
      "Epoch[11/15], Step [30/469], Reconst Loss: 9834.0117, KL Div: 3228.7622\n",
      "Epoch[11/15], Step [40/469], Reconst Loss: 10007.8799, KL Div: 3089.1714\n",
      "Epoch[11/15], Step [50/469], Reconst Loss: 10320.7656, KL Div: 3211.1165\n",
      "Epoch[11/15], Step [60/469], Reconst Loss: 10193.2383, KL Div: 3179.3208\n",
      "Epoch[11/15], Step [70/469], Reconst Loss: 10420.4912, KL Div: 3271.5549\n",
      "Epoch[11/15], Step [80/469], Reconst Loss: 10495.7949, KL Div: 3336.1421\n",
      "Epoch[11/15], Step [90/469], Reconst Loss: 10337.5156, KL Div: 3209.5127\n",
      "Epoch[11/15], Step [100/469], Reconst Loss: 10098.4766, KL Div: 3152.4148\n",
      "Epoch[11/15], Step [110/469], Reconst Loss: 11063.3525, KL Div: 3304.7520\n",
      "Epoch[11/15], Step [120/469], Reconst Loss: 10218.6777, KL Div: 3208.5000\n",
      "Epoch[11/15], Step [130/469], Reconst Loss: 10197.9541, KL Div: 3175.2866\n",
      "Epoch[11/15], Step [140/469], Reconst Loss: 10518.5430, KL Div: 3227.1787\n",
      "Epoch[11/15], Step [150/469], Reconst Loss: 10514.9531, KL Div: 3330.8762\n",
      "Epoch[11/15], Step [160/469], Reconst Loss: 10476.5166, KL Div: 3173.1194\n",
      "Epoch[11/15], Step [170/469], Reconst Loss: 10422.6855, KL Div: 3304.3694\n",
      "Epoch[11/15], Step [180/469], Reconst Loss: 10574.7236, KL Div: 3186.1772\n",
      "Epoch[11/15], Step [190/469], Reconst Loss: 10752.8555, KL Div: 3225.4390\n",
      "Epoch[11/15], Step [200/469], Reconst Loss: 10185.0918, KL Div: 3210.9502\n",
      "Epoch[11/15], Step [210/469], Reconst Loss: 10477.6221, KL Div: 3190.9473\n",
      "Epoch[11/15], Step [220/469], Reconst Loss: 10783.1943, KL Div: 3259.9856\n",
      "Epoch[11/15], Step [230/469], Reconst Loss: 10078.3457, KL Div: 3254.4175\n",
      "Epoch[11/15], Step [240/469], Reconst Loss: 10350.5391, KL Div: 3304.8262\n",
      "Epoch[11/15], Step [250/469], Reconst Loss: 10405.2734, KL Div: 3176.6541\n",
      "Epoch[11/15], Step [260/469], Reconst Loss: 9731.6514, KL Div: 3291.6062\n",
      "Epoch[11/15], Step [270/469], Reconst Loss: 10380.9570, KL Div: 3229.0417\n",
      "Epoch[11/15], Step [280/469], Reconst Loss: 10168.9023, KL Div: 3242.1462\n",
      "Epoch[11/15], Step [290/469], Reconst Loss: 10362.5039, KL Div: 3265.9087\n",
      "Epoch[11/15], Step [300/469], Reconst Loss: 9958.9473, KL Div: 3231.9690\n",
      "Epoch[11/15], Step [310/469], Reconst Loss: 10429.1084, KL Div: 3297.1409\n",
      "Epoch[11/15], Step [320/469], Reconst Loss: 9937.6777, KL Div: 3243.2661\n",
      "Epoch[11/15], Step [330/469], Reconst Loss: 10417.7832, KL Div: 3250.0308\n",
      "Epoch[11/15], Step [340/469], Reconst Loss: 10252.0020, KL Div: 3237.6404\n",
      "Epoch[11/15], Step [350/469], Reconst Loss: 10045.1562, KL Div: 3296.9407\n",
      "Epoch[11/15], Step [360/469], Reconst Loss: 10503.2920, KL Div: 3297.5437\n",
      "Epoch[11/15], Step [370/469], Reconst Loss: 9957.2393, KL Div: 3260.9111\n",
      "Epoch[11/15], Step [380/469], Reconst Loss: 10204.5654, KL Div: 3268.3494\n",
      "Epoch[11/15], Step [390/469], Reconst Loss: 10302.5430, KL Div: 3148.2808\n",
      "Epoch[11/15], Step [400/469], Reconst Loss: 10017.7402, KL Div: 3284.0894\n",
      "Epoch[11/15], Step [410/469], Reconst Loss: 10120.2764, KL Div: 3266.6147\n",
      "Epoch[11/15], Step [420/469], Reconst Loss: 10229.5576, KL Div: 3203.0884\n",
      "Epoch[11/15], Step [430/469], Reconst Loss: 10524.9648, KL Div: 3239.2617\n",
      "Epoch[11/15], Step [440/469], Reconst Loss: 10534.7461, KL Div: 3237.7798\n",
      "Epoch[11/15], Step [450/469], Reconst Loss: 10175.3115, KL Div: 3295.1379\n",
      "Epoch[11/15], Step [460/469], Reconst Loss: 10032.7441, KL Div: 3242.7607\n",
      "Epoch[12/15], Step [10/469], Reconst Loss: 9844.8682, KL Div: 3251.5200\n",
      "Epoch[12/15], Step [20/469], Reconst Loss: 10411.7031, KL Div: 3058.4319\n",
      "Epoch[12/15], Step [30/469], Reconst Loss: 10184.2324, KL Div: 3306.6855\n",
      "Epoch[12/15], Step [40/469], Reconst Loss: 10347.3584, KL Div: 3215.3320\n",
      "Epoch[12/15], Step [50/469], Reconst Loss: 9999.2949, KL Div: 3180.1206\n",
      "Epoch[12/15], Step [60/469], Reconst Loss: 10480.5938, KL Div: 3281.3613\n",
      "Epoch[12/15], Step [70/469], Reconst Loss: 10528.5938, KL Div: 3156.5303\n",
      "Epoch[12/15], Step [80/469], Reconst Loss: 10318.7646, KL Div: 3234.8313\n",
      "Epoch[12/15], Step [90/469], Reconst Loss: 9871.6914, KL Div: 3173.5840\n",
      "Epoch[12/15], Step [100/469], Reconst Loss: 10786.3457, KL Div: 3326.0962\n",
      "Epoch[12/15], Step [110/469], Reconst Loss: 10647.6230, KL Div: 3303.1116\n",
      "Epoch[12/15], Step [120/469], Reconst Loss: 10328.2363, KL Div: 3218.4194\n",
      "Epoch[12/15], Step [130/469], Reconst Loss: 9689.3369, KL Div: 3233.1016\n",
      "Epoch[12/15], Step [140/469], Reconst Loss: 10327.9395, KL Div: 3254.8926\n",
      "Epoch[12/15], Step [150/469], Reconst Loss: 10101.9346, KL Div: 3150.8777\n",
      "Epoch[12/15], Step [160/469], Reconst Loss: 10448.8516, KL Div: 3343.1804\n",
      "Epoch[12/15], Step [170/469], Reconst Loss: 10057.6543, KL Div: 3216.4353\n",
      "Epoch[12/15], Step [180/469], Reconst Loss: 10774.6670, KL Div: 3318.0833\n",
      "Epoch[12/15], Step [190/469], Reconst Loss: 10242.1426, KL Div: 3208.6387\n",
      "Epoch[12/15], Step [200/469], Reconst Loss: 9877.8428, KL Div: 3053.0925\n",
      "Epoch[12/15], Step [210/469], Reconst Loss: 10051.0117, KL Div: 3189.8384\n",
      "Epoch[12/15], Step [220/469], Reconst Loss: 9993.9111, KL Div: 3216.1626\n",
      "Epoch[12/15], Step [230/469], Reconst Loss: 10311.8652, KL Div: 3286.2043\n",
      "Epoch[12/15], Step [240/469], Reconst Loss: 9958.7803, KL Div: 3188.3452\n",
      "Epoch[12/15], Step [250/469], Reconst Loss: 10196.6152, KL Div: 3199.1838\n",
      "Epoch[12/15], Step [260/469], Reconst Loss: 10429.5020, KL Div: 3315.5413\n",
      "Epoch[12/15], Step [270/469], Reconst Loss: 10346.1875, KL Div: 3316.5981\n",
      "Epoch[12/15], Step [280/469], Reconst Loss: 10256.4004, KL Div: 3117.6658\n",
      "Epoch[12/15], Step [290/469], Reconst Loss: 10117.7607, KL Div: 3156.5532\n",
      "Epoch[12/15], Step [300/469], Reconst Loss: 9899.0605, KL Div: 3332.8030\n",
      "Epoch[12/15], Step [310/469], Reconst Loss: 9921.2314, KL Div: 3057.2214\n",
      "Epoch[12/15], Step [320/469], Reconst Loss: 10043.3652, KL Div: 3209.0249\n",
      "Epoch[12/15], Step [330/469], Reconst Loss: 10210.4717, KL Div: 3319.4746\n",
      "Epoch[12/15], Step [340/469], Reconst Loss: 10515.1172, KL Div: 3259.4836\n",
      "Epoch[12/15], Step [350/469], Reconst Loss: 10239.4639, KL Div: 3127.1177\n",
      "Epoch[12/15], Step [360/469], Reconst Loss: 10503.3779, KL Div: 3284.2964\n",
      "Epoch[12/15], Step [370/469], Reconst Loss: 10006.9492, KL Div: 3158.2273\n",
      "Epoch[12/15], Step [380/469], Reconst Loss: 10137.9092, KL Div: 3276.4150\n",
      "Epoch[12/15], Step [390/469], Reconst Loss: 9857.8389, KL Div: 3292.5317\n",
      "Epoch[12/15], Step [400/469], Reconst Loss: 10375.8564, KL Div: 3137.2866\n",
      "Epoch[12/15], Step [410/469], Reconst Loss: 9927.6709, KL Div: 3219.7661\n",
      "Epoch[12/15], Step [420/469], Reconst Loss: 10604.7031, KL Div: 3154.0532\n",
      "Epoch[12/15], Step [430/469], Reconst Loss: 9642.1504, KL Div: 3112.7922\n",
      "Epoch[12/15], Step [440/469], Reconst Loss: 10810.1426, KL Div: 3425.6772\n",
      "Epoch[12/15], Step [450/469], Reconst Loss: 10423.8643, KL Div: 3257.3135\n",
      "Epoch[12/15], Step [460/469], Reconst Loss: 9968.8027, KL Div: 3095.2866\n",
      "Epoch[13/15], Step [10/469], Reconst Loss: 10278.1377, KL Div: 3226.6475\n",
      "Epoch[13/15], Step [20/469], Reconst Loss: 10632.4561, KL Div: 3317.1411\n",
      "Epoch[13/15], Step [30/469], Reconst Loss: 10555.6074, KL Div: 3348.9751\n",
      "Epoch[13/15], Step [40/469], Reconst Loss: 10372.9219, KL Div: 3280.9570\n",
      "Epoch[13/15], Step [50/469], Reconst Loss: 10166.3848, KL Div: 3285.2700\n",
      "Epoch[13/15], Step [60/469], Reconst Loss: 10325.7373, KL Div: 3196.0911\n",
      "Epoch[13/15], Step [70/469], Reconst Loss: 10383.8711, KL Div: 3191.1855\n",
      "Epoch[13/15], Step [80/469], Reconst Loss: 10113.1895, KL Div: 3316.5566\n",
      "Epoch[13/15], Step [90/469], Reconst Loss: 11205.2314, KL Div: 3283.3013\n",
      "Epoch[13/15], Step [100/469], Reconst Loss: 10378.7744, KL Div: 3316.4265\n",
      "Epoch[13/15], Step [110/469], Reconst Loss: 10373.4355, KL Div: 3240.0869\n",
      "Epoch[13/15], Step [120/469], Reconst Loss: 10228.4629, KL Div: 3232.2915\n",
      "Epoch[13/15], Step [130/469], Reconst Loss: 10157.3516, KL Div: 3234.3918\n",
      "Epoch[13/15], Step [140/469], Reconst Loss: 10142.3389, KL Div: 3258.1182\n",
      "Epoch[13/15], Step [150/469], Reconst Loss: 10137.0732, KL Div: 3163.8821\n",
      "Epoch[13/15], Step [160/469], Reconst Loss: 10252.1787, KL Div: 3246.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13/15], Step [170/469], Reconst Loss: 10203.2715, KL Div: 3261.6396\n",
      "Epoch[13/15], Step [180/469], Reconst Loss: 10144.8242, KL Div: 3158.9033\n",
      "Epoch[13/15], Step [190/469], Reconst Loss: 10921.6016, KL Div: 3313.9661\n",
      "Epoch[13/15], Step [200/469], Reconst Loss: 10501.3506, KL Div: 3225.2344\n",
      "Epoch[13/15], Step [210/469], Reconst Loss: 10507.0234, KL Div: 3349.1211\n",
      "Epoch[13/15], Step [220/469], Reconst Loss: 10586.5664, KL Div: 3330.4104\n",
      "Epoch[13/15], Step [230/469], Reconst Loss: 10435.7363, KL Div: 3299.5688\n",
      "Epoch[13/15], Step [240/469], Reconst Loss: 10150.3145, KL Div: 3199.0957\n",
      "Epoch[13/15], Step [250/469], Reconst Loss: 10203.2383, KL Div: 3119.7700\n",
      "Epoch[13/15], Step [260/469], Reconst Loss: 10131.3535, KL Div: 3319.7878\n",
      "Epoch[13/15], Step [270/469], Reconst Loss: 10270.8330, KL Div: 3176.0291\n",
      "Epoch[13/15], Step [280/469], Reconst Loss: 10661.6328, KL Div: 3183.1987\n",
      "Epoch[13/15], Step [290/469], Reconst Loss: 10101.1094, KL Div: 3351.9463\n",
      "Epoch[13/15], Step [300/469], Reconst Loss: 10350.6855, KL Div: 3268.0525\n",
      "Epoch[13/15], Step [310/469], Reconst Loss: 10140.3320, KL Div: 3112.6213\n",
      "Epoch[13/15], Step [320/469], Reconst Loss: 10177.3369, KL Div: 3351.0591\n",
      "Epoch[13/15], Step [330/469], Reconst Loss: 10700.8262, KL Div: 3278.0037\n",
      "Epoch[13/15], Step [340/469], Reconst Loss: 10151.6895, KL Div: 3159.4326\n",
      "Epoch[13/15], Step [350/469], Reconst Loss: 10519.4502, KL Div: 3307.2537\n",
      "Epoch[13/15], Step [360/469], Reconst Loss: 10029.2646, KL Div: 3130.4692\n",
      "Epoch[13/15], Step [370/469], Reconst Loss: 10303.1436, KL Div: 3263.4822\n",
      "Epoch[13/15], Step [380/469], Reconst Loss: 10200.1562, KL Div: 3252.6963\n",
      "Epoch[13/15], Step [390/469], Reconst Loss: 10274.7666, KL Div: 3295.5649\n",
      "Epoch[13/15], Step [400/469], Reconst Loss: 10350.3936, KL Div: 3297.7568\n",
      "Epoch[13/15], Step [410/469], Reconst Loss: 10173.2285, KL Div: 3243.6387\n",
      "Epoch[13/15], Step [420/469], Reconst Loss: 10187.4688, KL Div: 3293.8569\n",
      "Epoch[13/15], Step [430/469], Reconst Loss: 10231.4971, KL Div: 3101.7803\n",
      "Epoch[13/15], Step [440/469], Reconst Loss: 10350.0557, KL Div: 3173.9546\n",
      "Epoch[13/15], Step [450/469], Reconst Loss: 10335.1289, KL Div: 3303.6133\n",
      "Epoch[13/15], Step [460/469], Reconst Loss: 10271.6758, KL Div: 3234.8186\n",
      "Epoch[14/15], Step [10/469], Reconst Loss: 9957.6152, KL Div: 3330.8193\n",
      "Epoch[14/15], Step [20/469], Reconst Loss: 10063.4785, KL Div: 3143.1030\n",
      "Epoch[14/15], Step [30/469], Reconst Loss: 10371.9756, KL Div: 3228.7024\n",
      "Epoch[14/15], Step [40/469], Reconst Loss: 10240.2207, KL Div: 3318.5972\n",
      "Epoch[14/15], Step [50/469], Reconst Loss: 10283.5527, KL Div: 3218.0474\n",
      "Epoch[14/15], Step [60/469], Reconst Loss: 9744.0664, KL Div: 3042.6162\n",
      "Epoch[14/15], Step [70/469], Reconst Loss: 10676.8018, KL Div: 3352.0518\n",
      "Epoch[14/15], Step [80/469], Reconst Loss: 10049.9932, KL Div: 3345.9531\n",
      "Epoch[14/15], Step [90/469], Reconst Loss: 10436.1885, KL Div: 3252.3701\n",
      "Epoch[14/15], Step [100/469], Reconst Loss: 10528.2227, KL Div: 3312.4041\n",
      "Epoch[14/15], Step [110/469], Reconst Loss: 9851.7500, KL Div: 3231.4546\n",
      "Epoch[14/15], Step [120/469], Reconst Loss: 10072.3564, KL Div: 3209.8850\n",
      "Epoch[14/15], Step [130/469], Reconst Loss: 10024.0156, KL Div: 3237.0332\n",
      "Epoch[14/15], Step [140/469], Reconst Loss: 10109.4600, KL Div: 3261.7029\n",
      "Epoch[14/15], Step [150/469], Reconst Loss: 9988.8252, KL Div: 3158.5859\n",
      "Epoch[14/15], Step [160/469], Reconst Loss: 10351.7139, KL Div: 3309.4331\n",
      "Epoch[14/15], Step [170/469], Reconst Loss: 9789.5957, KL Div: 3164.9229\n",
      "Epoch[14/15], Step [180/469], Reconst Loss: 9762.6943, KL Div: 3068.4097\n",
      "Epoch[14/15], Step [190/469], Reconst Loss: 9724.9092, KL Div: 3211.4624\n",
      "Epoch[14/15], Step [200/469], Reconst Loss: 10352.0332, KL Div: 3274.1768\n",
      "Epoch[14/15], Step [210/469], Reconst Loss: 10456.6309, KL Div: 3217.9155\n",
      "Epoch[14/15], Step [220/469], Reconst Loss: 10130.3672, KL Div: 3217.0247\n",
      "Epoch[14/15], Step [230/469], Reconst Loss: 9964.4043, KL Div: 3191.8906\n",
      "Epoch[14/15], Step [240/469], Reconst Loss: 10182.7227, KL Div: 3257.3762\n",
      "Epoch[14/15], Step [250/469], Reconst Loss: 10362.4570, KL Div: 3225.6016\n",
      "Epoch[14/15], Step [260/469], Reconst Loss: 10303.6553, KL Div: 3164.5151\n",
      "Epoch[14/15], Step [270/469], Reconst Loss: 10094.0234, KL Div: 3255.8848\n",
      "Epoch[14/15], Step [280/469], Reconst Loss: 9895.6934, KL Div: 3168.7017\n",
      "Epoch[14/15], Step [290/469], Reconst Loss: 9837.9648, KL Div: 3200.6499\n",
      "Epoch[14/15], Step [300/469], Reconst Loss: 9967.6455, KL Div: 3145.8286\n",
      "Epoch[14/15], Step [310/469], Reconst Loss: 10591.5742, KL Div: 3280.3975\n",
      "Epoch[14/15], Step [320/469], Reconst Loss: 10336.5811, KL Div: 3233.5132\n",
      "Epoch[14/15], Step [330/469], Reconst Loss: 9863.1006, KL Div: 3162.3096\n",
      "Epoch[14/15], Step [340/469], Reconst Loss: 10294.5947, KL Div: 3274.6216\n",
      "Epoch[14/15], Step [350/469], Reconst Loss: 10483.7725, KL Div: 3286.8394\n",
      "Epoch[14/15], Step [360/469], Reconst Loss: 10314.3057, KL Div: 3282.9126\n",
      "Epoch[14/15], Step [370/469], Reconst Loss: 10173.9766, KL Div: 3257.0627\n",
      "Epoch[14/15], Step [380/469], Reconst Loss: 10331.0586, KL Div: 3251.6814\n",
      "Epoch[14/15], Step [390/469], Reconst Loss: 10121.1250, KL Div: 3268.1936\n",
      "Epoch[14/15], Step [400/469], Reconst Loss: 9832.1104, KL Div: 3170.7192\n",
      "Epoch[14/15], Step [410/469], Reconst Loss: 9932.6582, KL Div: 3206.6309\n",
      "Epoch[14/15], Step [420/469], Reconst Loss: 9988.9297, KL Div: 3292.0620\n",
      "Epoch[14/15], Step [430/469], Reconst Loss: 10086.5234, KL Div: 3203.4224\n",
      "Epoch[14/15], Step [440/469], Reconst Loss: 9704.9785, KL Div: 3185.4409\n",
      "Epoch[14/15], Step [450/469], Reconst Loss: 10520.6699, KL Div: 3252.0664\n",
      "Epoch[14/15], Step [460/469], Reconst Loss: 10459.7773, KL Div: 3301.6064\n",
      "Epoch[15/15], Step [10/469], Reconst Loss: 10530.1709, KL Div: 3274.5671\n",
      "Epoch[15/15], Step [20/469], Reconst Loss: 10221.2314, KL Div: 3253.3193\n",
      "Epoch[15/15], Step [30/469], Reconst Loss: 10694.0596, KL Div: 3306.9526\n",
      "Epoch[15/15], Step [40/469], Reconst Loss: 10062.9346, KL Div: 3218.0100\n",
      "Epoch[15/15], Step [50/469], Reconst Loss: 10277.9375, KL Div: 3228.9575\n",
      "Epoch[15/15], Step [60/469], Reconst Loss: 9939.4316, KL Div: 3267.9756\n",
      "Epoch[15/15], Step [70/469], Reconst Loss: 9922.7168, KL Div: 3123.9502\n",
      "Epoch[15/15], Step [80/469], Reconst Loss: 10352.9941, KL Div: 3270.1250\n",
      "Epoch[15/15], Step [90/469], Reconst Loss: 9604.1543, KL Div: 3103.7485\n",
      "Epoch[15/15], Step [100/469], Reconst Loss: 10182.9043, KL Div: 3188.4756\n",
      "Epoch[15/15], Step [110/469], Reconst Loss: 9812.0010, KL Div: 3090.3701\n",
      "Epoch[15/15], Step [120/469], Reconst Loss: 9895.6436, KL Div: 3178.5486\n",
      "Epoch[15/15], Step [130/469], Reconst Loss: 10686.8301, KL Div: 3253.2502\n",
      "Epoch[15/15], Step [140/469], Reconst Loss: 10006.8086, KL Div: 3222.5469\n",
      "Epoch[15/15], Step [150/469], Reconst Loss: 9913.7842, KL Div: 3184.6860\n",
      "Epoch[15/15], Step [160/469], Reconst Loss: 10098.4082, KL Div: 3252.1924\n",
      "Epoch[15/15], Step [170/469], Reconst Loss: 10658.8320, KL Div: 3411.8027\n",
      "Epoch[15/15], Step [180/469], Reconst Loss: 10204.3965, KL Div: 3298.9702\n",
      "Epoch[15/15], Step [190/469], Reconst Loss: 10155.3896, KL Div: 3205.5479\n",
      "Epoch[15/15], Step [200/469], Reconst Loss: 10552.0557, KL Div: 3241.8389\n",
      "Epoch[15/15], Step [210/469], Reconst Loss: 10303.8809, KL Div: 3318.2249\n",
      "Epoch[15/15], Step [220/469], Reconst Loss: 10024.6309, KL Div: 3285.3750\n",
      "Epoch[15/15], Step [230/469], Reconst Loss: 9949.9795, KL Div: 3236.6687\n",
      "Epoch[15/15], Step [240/469], Reconst Loss: 10055.1377, KL Div: 3272.2549\n",
      "Epoch[15/15], Step [250/469], Reconst Loss: 10371.3730, KL Div: 3349.1384\n",
      "Epoch[15/15], Step [260/469], Reconst Loss: 10587.7568, KL Div: 3351.4792\n",
      "Epoch[15/15], Step [270/469], Reconst Loss: 10520.1084, KL Div: 3245.3374\n",
      "Epoch[15/15], Step [280/469], Reconst Loss: 9795.1016, KL Div: 3141.0581\n",
      "Epoch[15/15], Step [290/469], Reconst Loss: 10124.2734, KL Div: 3243.3291\n",
      "Epoch[15/15], Step [300/469], Reconst Loss: 9906.0664, KL Div: 3251.9209\n",
      "Epoch[15/15], Step [310/469], Reconst Loss: 10577.9629, KL Div: 3317.4807\n",
      "Epoch[15/15], Step [320/469], Reconst Loss: 10363.2520, KL Div: 3249.1421\n",
      "Epoch[15/15], Step [330/469], Reconst Loss: 9936.9199, KL Div: 3244.0601\n",
      "Epoch[15/15], Step [340/469], Reconst Loss: 9950.1963, KL Div: 3222.7095\n",
      "Epoch[15/15], Step [350/469], Reconst Loss: 10357.5107, KL Div: 3198.4814\n",
      "Epoch[15/15], Step [360/469], Reconst Loss: 10414.2109, KL Div: 3324.8730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[15/15], Step [370/469], Reconst Loss: 9842.3027, KL Div: 3237.9448\n",
      "Epoch[15/15], Step [380/469], Reconst Loss: 10065.6494, KL Div: 3364.7686\n",
      "Epoch[15/15], Step [390/469], Reconst Loss: 10405.9160, KL Div: 3285.6794\n",
      "Epoch[15/15], Step [400/469], Reconst Loss: 9962.2441, KL Div: 3145.6050\n",
      "Epoch[15/15], Step [410/469], Reconst Loss: 9827.7695, KL Div: 3243.9824\n",
      "Epoch[15/15], Step [420/469], Reconst Loss: 10238.7061, KL Div: 3214.7231\n",
      "Epoch[15/15], Step [430/469], Reconst Loss: 9938.4424, KL Div: 3316.8372\n",
      "Epoch[15/15], Step [440/469], Reconst Loss: 9795.4902, KL Div: 3232.6538\n",
      "Epoch[15/15], Step [450/469], Reconst Loss: 10114.7959, KL Div: 3274.0791\n",
      "Epoch[15/15], Step [460/469], Reconst Loss: 9888.8770, KL Div: 3240.9622\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create a directory if not exists\n",
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "# Hyper-parameters\n",
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 15\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# MNIST dataset\n",
    "dataset = torchvision.datasets.MNIST(root='../../data',\n",
    "                                     train=True,\n",
    "                                     transform=transforms.ToTensor(),\n",
    "                                     download=True)\n",
    "print(\"data : \" + str(len(dataset)) + ' images')\n",
    "\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)\n",
    "\n",
    "\n",
    "# VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var\n",
    "\n",
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        # Forward pass\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "        \n",
    "        # Compute reconstruction loss and kl divergence\n",
    "        # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n",
    "                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(10, z_dim).to(device)\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\n",
    "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "\n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
