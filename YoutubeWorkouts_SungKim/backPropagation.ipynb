{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np     # convenient matrix, tensor-like operations\n",
    "import matplotlib.pyplot as plt     # plotting tool\n",
    "import torch\n",
    "from torch.autograd import variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashish/anaconda2/lib/python2.7/site-packages/torch/autograd/__init__.py:166: UserWarning: torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\n",
      "  warnings.warn(\"torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\")\n"
     ]
    }
   ],
   "source": [
    "w=variable(torch.Tensor([1.0]), requires_grad=True)\n",
    "alpha=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Forward pass\n",
    "def forward(x):\n",
    "    return x * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loss function\n",
    "def loss(x, y):\n",
    "    y_pred=forward(x)\n",
    "    return (y-y_pred)*(y-y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('predict (before training)', 4)\n"
     ]
    }
   ],
   "source": [
    "#Before training\n",
    "print(\"predict (before training)\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\t grad:', 1.0, 2.0, tensor(-2.))\n",
      "('\\t grad:', 2.0, 4.0, tensor(-9.8400))\n",
      "('\\t grad:', 3.0, 6.0, tensor(-25.7088))\n",
      "('progress:', 0, 'w=', tensor([ 1.3755]), 'loss', tensor([ 6.9950]))\n",
      "('\\t grad:', 1.0, 2.0, tensor(-1.2490))\n",
      "('\\t grad:', 2.0, 4.0, tensor(-6.1452))\n",
      "('\\t grad:', 3.0, 6.0, tensor(-16.0555))\n",
      "('progress:', 1, 'w=', tensor([ 1.6100]), 'loss', tensor([ 2.7281]))\n",
      "('\\t grad:', 1.0, 2.0, tensor(-0.7800))\n",
      "('\\t grad:', 2.0, 4.0, tensor(-3.8377))\n",
      "('\\t grad:', 3.0, 6.0, tensor(-10.0268))\n",
      "('progress:', 2, 'w=', tensor([ 1.7564]), 'loss', tensor([ 1.0640]))\n",
      "('\\t grad:', 1.0, 2.0, tensor(-0.4871))\n",
      "('\\t grad:', 2.0, 4.0, tensor(-2.3967))\n",
      "('\\t grad:', 3.0, 6.0, tensor(-6.2619))\n",
      "('progress:', 3, 'w=', tensor([ 1.8479]), 'loss', tensor([ 0.4150]))\n",
      "('\\t grad:', 1.0, 2.0, tensor(-0.3042))\n",
      "('\\t grad:', 2.0, 4.0, tensor(-1.4968))\n",
      "('\\t grad:', 3.0, 6.0, tensor(-3.9106))\n",
      "('progress:', 4, 'w=', tensor([ 1.9050]), 'loss', tensor([ 0.1618]))\n",
      "('\\t grad:', 1.0, 2.0, tensor(-0.1900))\n",
      "('\\t grad:', 2.0, 4.0, tensor(-0.9348))\n",
      "('\\t grad:', 3.0, 6.0, tensor(-2.4422))\n",
      "('progress:', 5, 'w=', tensor([ 1.9407]), 'loss', tensor(1.00000e-02 *\n",
      "       [ 6.3124]))\n",
      "('\\t grad:', 1.0, 2.0, tensor(-0.1187))\n",
      "('\\t grad:', 2.0, 4.0, tensor(-0.5838))\n",
      "('\\t grad:', 3.0, 6.0, tensor(-1.5252))\n",
      "('progress:', 6, 'w=', tensor([ 1.9630]), 'loss', tensor(1.00000e-02 *\n",
      "       [ 2.4619]))\n",
      "('\\t grad:', 1.0, 2.0, tensor(1.00000e-02 *\n",
      "       -7.4100))\n",
      "('\\t grad:', 2.0, 4.0, tensor(-0.3646))\n",
      "('\\t grad:', 3.0, 6.0, tensor(-0.9525))\n",
      "('progress:', 7, 'w=', tensor([ 1.9769]), 'loss', tensor(1.00000e-03 *\n",
      "       [ 9.6019]))\n",
      "('\\t grad:', 1.0, 2.0, tensor(1.00000e-02 *\n",
      "       -4.6276))\n",
      "('\\t grad:', 2.0, 4.0, tensor(-0.2277))\n",
      "('\\t grad:', 3.0, 6.0, tensor(-0.5949))\n",
      "('progress:', 8, 'w=', tensor([ 1.9856]), 'loss', tensor(1.00000e-03 *\n",
      "       [ 3.7449]))\n",
      "('\\t grad:', 1.0, 2.0, tensor(1.00000e-02 *\n",
      "       -2.8900))\n",
      "('\\t grad:', 2.0, 4.0, tensor(-0.1422))\n",
      "('\\t grad:', 3.0, 6.0, tensor(-0.3715))\n",
      "('progress:', 9, 'w=', tensor([ 1.9910]), 'loss', tensor(1.00000e-03 *\n",
      "       [ 1.4605]))\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "for epoch in range(10):\n",
    "    for x,y in zip(x_data , y_data):\n",
    "        l=loss(x,y)\n",
    "        l.backward()\n",
    "        print(\"\\t grad:\", x, y, w.grad.data[0])\n",
    "        w.data = w.data - alpha * w.grad.data\n",
    "        \n",
    "    #Manually zero the gradients after updating weights\n",
    "    w.grad.data.zero_()\n",
    "      \n",
    "    print(\"progress:\", epoch, \"w=\",w, \"loss\", l)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
